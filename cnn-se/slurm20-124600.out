/var/spool/slurm/d/job124600/slurm_script: line 6: /vol/cuda/11.8/setup.sh: No such file or directory
Thu Jul 18 02:04:37 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Tesla T4                       Off | 00000000:00:06.0 Off |                    0 |
| N/A   38C    P8              14W /  70W |      2MiB / 15360MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199412/199412.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200309/200309.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/198104/198104.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/198919/198919.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/198605/198605.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/198708/198708.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200505/200505.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/198616/198616.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199003/199003.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201209/201209.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200715/200715.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200119/200119.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200424/200424.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201601/201601.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/202114/202114.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199219/199219.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199017/199017.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199716/199716.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201416/201416.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/202109/202109.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201214/201214.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/198408/198408.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200708/200708.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200605/200605.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200807/200807.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200420/200420.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200010/200010.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199810/199810.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201307/201307.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199405/199405.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200427/200427.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/198706/198706.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199809/199809.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/198209/198209.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200004/200004.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200813/200813.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199801/199801.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200707/200707.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200208/200208.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199005/199005.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200808/200808.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199609/199609.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/198212/198212.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200908/200908.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201205/201205.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200020/200020.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201410/201410.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199413/199413.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/198105/198105.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199215/199215.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200609/200609.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201111/201111.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199802/199802.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201521/201521.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201315/201315.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200407/200407.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199417/199417.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201513/201513.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200108/200108.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200519/200519.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200513/200513.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/198802/198802.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200116/200116.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201709/201709.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/198614/198614.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200105/200105.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201617/201617.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/200815/200815.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201710/201710.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199216/199216.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201011/201011.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/199012/199012.zarr
Found zarr directory: /vol/bitbucket/zl1823/Typhoon-forecasting/dataset/pre_processed_dataset/ERA5_without_nan_taiwan/201806/201806.zarr
Train dataset length: 1267
Validation dataset length: 281
Test dataset length: 283
Finetuning CNN Model:
Training with batch_size=32 and learning_rate=1e-05
Epoch [1/200], Average Training Loss: 0.3164
Epoch [1/200], Validation Loss: 0.2869
Epoch [2/200], Average Training Loss: 0.2483
Epoch [2/200], Validation Loss: 0.1977
Epoch [3/200], Average Training Loss: 0.2124
Epoch [3/200], Validation Loss: 0.1771
Epoch [4/200], Average Training Loss: 0.1975
Epoch [4/200], Validation Loss: 0.1653
Epoch [5/200], Average Training Loss: 0.1890
Epoch [5/200], Validation Loss: 0.1510
Epoch [6/200], Average Training Loss: 0.1820
Epoch [6/200], Validation Loss: 0.1429
Epoch [7/200], Average Training Loss: 0.1766
Epoch [7/200], Validation Loss: 0.1372
Epoch [8/200], Average Training Loss: 0.1730
Epoch [8/200], Validation Loss: 0.1324
Epoch [9/200], Average Training Loss: 0.1665
Epoch [9/200], Validation Loss: 0.1334
Epoch [10/200], Average Training Loss: 0.1663
Epoch [10/200], Validation Loss: 0.1271
Epoch [11/200], Average Training Loss: 0.1616
Epoch [11/200], Validation Loss: 0.1222
Epoch [12/200], Average Training Loss: 0.1630
Epoch [12/200], Validation Loss: 0.1216
Epoch [13/200], Average Training Loss: 0.1569
Epoch [13/200], Validation Loss: 0.1163
Epoch [14/200], Average Training Loss: 0.1552
Epoch [14/200], Validation Loss: 0.1146
Epoch [15/200], Average Training Loss: 0.1569
Epoch [15/200], Validation Loss: 0.1136
Epoch [16/200], Average Training Loss: 0.1537
Epoch [16/200], Validation Loss: 0.1128
Epoch [17/200], Average Training Loss: 0.1508
Epoch [17/200], Validation Loss: 0.1121
Epoch [18/200], Average Training Loss: 0.1514
Epoch [18/200], Validation Loss: 0.1112
Epoch [19/200], Average Training Loss: 0.1478
Epoch [19/200], Validation Loss: 0.1115
Epoch [20/200], Average Training Loss: 0.1453
Epoch [20/200], Validation Loss: 0.1096
Epoch [21/200], Average Training Loss: 0.1463
Epoch [21/200], Validation Loss: 0.1084
Epoch [22/200], Average Training Loss: 0.1440
Epoch [22/200], Validation Loss: 0.1093
Epoch [23/200], Average Training Loss: 0.1430
Epoch [23/200], Validation Loss: 0.1132
Epoch [24/200], Average Training Loss: 0.1384
Epoch [24/200], Validation Loss: 0.1023
Epoch [25/200], Average Training Loss: 0.1378
Epoch [25/200], Validation Loss: 0.1019
Epoch [26/200], Average Training Loss: 0.1362
Epoch [26/200], Validation Loss: 0.1196
Epoch [27/200], Average Training Loss: 0.1343
Epoch [27/200], Validation Loss: 0.1089
Epoch [28/200], Average Training Loss: 0.1329
Epoch [28/200], Validation Loss: 0.1030
Epoch [29/200], Average Training Loss: 0.1310
Epoch [29/200], Validation Loss: 0.1052
Epoch [30/200], Average Training Loss: 0.1310
Epoch [30/200], Validation Loss: 0.1074
Epoch [31/200], Average Training Loss: 0.1283
Epoch [31/200], Validation Loss: 0.0993
Epoch [32/200], Average Training Loss: 0.1291
Epoch [32/200], Validation Loss: 0.1022
Epoch [33/200], Average Training Loss: 0.1284
Epoch [33/200], Validation Loss: 0.1097
Epoch [34/200], Average Training Loss: 0.1268
Epoch [34/200], Validation Loss: 0.1027
Epoch [35/200], Average Training Loss: 0.1252
Epoch [35/200], Validation Loss: 0.0975
Epoch [36/200], Average Training Loss: 0.1211
Epoch [36/200], Validation Loss: 0.0968
Epoch [37/200], Average Training Loss: 0.1189
Epoch [37/200], Validation Loss: 0.1031
Epoch [38/200], Average Training Loss: 0.1194
Epoch [38/200], Validation Loss: 0.1016
Epoch [39/200], Average Training Loss: 0.1182
Epoch [39/200], Validation Loss: 0.1040
Epoch [40/200], Average Training Loss: 0.1183
Epoch [40/200], Validation Loss: 0.0988
Epoch [41/200], Average Training Loss: 0.1152
Epoch [41/200], Validation Loss: 0.1004
Epoch [42/200], Average Training Loss: 0.1150
Epoch [42/200], Validation Loss: 0.0977
Epoch [43/200], Average Training Loss: 0.1137
Epoch [43/200], Validation Loss: 0.0975
Epoch [44/200], Average Training Loss: 0.1115
Epoch [44/200], Validation Loss: 0.0961
Epoch [45/200], Average Training Loss: 0.1116
Epoch [45/200], Validation Loss: 0.0965
Epoch [46/200], Average Training Loss: 0.1113
Epoch [46/200], Validation Loss: 0.0951
Epoch [47/200], Average Training Loss: 0.1083
Epoch [47/200], Validation Loss: 0.0940
Epoch [48/200], Average Training Loss: 0.1074
Epoch [48/200], Validation Loss: 0.0926
Epoch [49/200], Average Training Loss: 0.1054
Epoch [49/200], Validation Loss: 0.0963
Epoch [50/200], Average Training Loss: 0.1085
Epoch [50/200], Validation Loss: 0.1144
Epoch [51/200], Average Training Loss: 0.1063
Epoch [51/200], Validation Loss: 0.0968
Epoch [52/200], Average Training Loss: 0.1043
Epoch [52/200], Validation Loss: 0.0998
Epoch [53/200], Average Training Loss: 0.1017
Epoch [53/200], Validation Loss: 0.0948
Epoch [54/200], Average Training Loss: 0.1013
Epoch [54/200], Validation Loss: 0.0931
Epoch [55/200], Average Training Loss: 0.0991
Epoch [55/200], Validation Loss: 0.0892
Epoch [56/200], Average Training Loss: 0.0960
Epoch [56/200], Validation Loss: 0.0893
Epoch [57/200], Average Training Loss: 0.0979
Epoch [57/200], Validation Loss: 0.0984
Epoch [58/200], Average Training Loss: 0.0967
Epoch [58/200], Validation Loss: 0.0947
Epoch [59/200], Average Training Loss: 0.0960
Epoch [59/200], Validation Loss: 0.0923
Epoch [60/200], Average Training Loss: 0.0937
Epoch [60/200], Validation Loss: 0.0874
Epoch [61/200], Average Training Loss: 0.0948
Epoch [61/200], Validation Loss: 0.0936
Epoch [62/200], Average Training Loss: 0.0917
Epoch [62/200], Validation Loss: 0.0945
Epoch [63/200], Average Training Loss: 0.0916
Epoch [63/200], Validation Loss: 0.0896
Epoch [64/200], Average Training Loss: 0.0918
Epoch [64/200], Validation Loss: 0.0918
Epoch [65/200], Average Training Loss: 0.0910
Epoch [65/200], Validation Loss: 0.0883
Epoch [66/200], Average Training Loss: 0.0871
Epoch [66/200], Validation Loss: 0.0952
Epoch [67/200], Average Training Loss: 0.0877
Epoch [67/200], Validation Loss: 0.0906
Epoch [68/200], Average Training Loss: 0.0872
Epoch [68/200], Validation Loss: 0.0913
Epoch [69/200], Average Training Loss: 0.0868
Epoch [69/200], Validation Loss: 0.0900
Epoch [70/200], Average Training Loss: 0.0852
Epoch [70/200], Validation Loss: 0.0939
Epoch [71/200], Average Training Loss: 0.0856
Epoch [71/200], Validation Loss: 0.0873
Epoch [72/200], Average Training Loss: 0.0847
Epoch [72/200], Validation Loss: 0.0945
Epoch [73/200], Average Training Loss: 0.0845
Epoch [73/200], Validation Loss: 0.0937
Epoch [74/200], Average Training Loss: 0.0832
Epoch [74/200], Validation Loss: 0.0904
Epoch [75/200], Average Training Loss: 0.0820
Epoch [75/200], Validation Loss: 0.0977
Epoch [76/200], Average Training Loss: 0.0822
Epoch [76/200], Validation Loss: 0.0974
Epoch [77/200], Average Training Loss: 0.0805
Epoch [77/200], Validation Loss: 0.0967
Epoch [78/200], Average Training Loss: 0.0793
Epoch [78/200], Validation Loss: 0.0930
Epoch [79/200], Average Training Loss: 0.0811
Epoch [79/200], Validation Loss: 0.0935
Epoch [80/200], Average Training Loss: 0.0793
Epoch [80/200], Validation Loss: 0.0946
Epoch [81/200], Average Training Loss: 0.0779
Epoch [81/200], Validation Loss: 0.0956
Epoch [82/200], Average Training Loss: 0.0763
Epoch [82/200], Validation Loss: 0.0919
Epoch [83/200], Average Training Loss: 0.0760
Epoch [83/200], Validation Loss: 0.0894
Epoch [84/200], Average Training Loss: 0.0761
Epoch [84/200], Validation Loss: 0.0931
Epoch [85/200], Average Training Loss: 0.0755
Epoch [85/200], Validation Loss: 0.0879
Epoch [86/200], Average Training Loss: 0.0758
Epoch [86/200], Validation Loss: 0.0886
Epoch [87/200], Average Training Loss: 0.0739
Epoch [87/200], Validation Loss: 0.0931
Epoch [88/200], Average Training Loss: 0.0735
Epoch [88/200], Validation Loss: 0.0919
Epoch [89/200], Average Training Loss: 0.0746
Epoch [89/200], Validation Loss: 0.0885
Epoch [90/200], Average Training Loss: 0.0725
Epoch [90/200], Validation Loss: 0.0919
Epoch [91/200], Average Training Loss: 0.0716
Epoch [91/200], Validation Loss: 0.0922
Early stopping at epoch 91
Finished Training
Training with batch_size=32 and learning_rate=0.0001
Epoch [1/200], Average Training Loss: 0.2469
Epoch [1/200], Validation Loss: 0.1890
Epoch [2/200], Average Training Loss: 0.1889
Epoch [2/200], Validation Loss: 0.1338
Epoch [3/200], Average Training Loss: 0.1675
Epoch [3/200], Validation Loss: 0.1405
Epoch [4/200], Average Training Loss: 0.1630
Epoch [4/200], Validation Loss: 0.1145
Epoch [5/200], Average Training Loss: 0.1539
Epoch [5/200], Validation Loss: 0.1170
Epoch [6/200], Average Training Loss: 0.1496
Epoch [6/200], Validation Loss: 0.1172
Epoch [7/200], Average Training Loss: 0.1437
Epoch [7/200], Validation Loss: 0.1188
Epoch [8/200], Average Training Loss: 0.1402
Epoch [8/200], Validation Loss: 0.1027
Epoch [9/200], Average Training Loss: 0.1343
Epoch [9/200], Validation Loss: 0.1113
Epoch [10/200], Average Training Loss: 0.1245
Epoch [10/200], Validation Loss: 0.0933
Epoch [11/200], Average Training Loss: 0.1282
Epoch [11/200], Validation Loss: 0.0986
Epoch [12/200], Average Training Loss: 0.1162
Epoch [12/200], Validation Loss: 0.0943
Epoch [13/200], Average Training Loss: 0.1124
Epoch [13/200], Validation Loss: 0.0881
Epoch [14/200], Average Training Loss: 0.1084
Epoch [14/200], Validation Loss: 0.0864
Epoch [15/200], Average Training Loss: 0.1016
Epoch [15/200], Validation Loss: 0.1031
Epoch [16/200], Average Training Loss: 0.0946
Epoch [16/200], Validation Loss: 0.0817
Epoch [17/200], Average Training Loss: 0.0935
Epoch [17/200], Validation Loss: 0.0938
Epoch [18/200], Average Training Loss: 0.0885
Epoch [18/200], Validation Loss: 0.0893
Epoch [19/200], Average Training Loss: 0.0854
Epoch [19/200], Validation Loss: 0.0818
Epoch [20/200], Average Training Loss: 0.0803
Epoch [20/200], Validation Loss: 0.0830
Epoch [21/200], Average Training Loss: 0.0786
Epoch [21/200], Validation Loss: 0.0828
Epoch [22/200], Average Training Loss: 0.0763
Epoch [22/200], Validation Loss: 0.0825
Epoch [23/200], Average Training Loss: 0.0726
Epoch [23/200], Validation Loss: 0.0796
Epoch [24/200], Average Training Loss: 0.0667
Epoch [24/200], Validation Loss: 0.0804
Epoch [25/200], Average Training Loss: 0.0663
Epoch [25/200], Validation Loss: 0.0854
Epoch [26/200], Average Training Loss: 0.0641
Epoch [26/200], Validation Loss: 0.0793
Epoch [27/200], Average Training Loss: 0.0606
Epoch [27/200], Validation Loss: 0.0725
Epoch [28/200], Average Training Loss: 0.0596
Epoch [28/200], Validation Loss: 0.0813
Epoch [29/200], Average Training Loss: 0.0569
Epoch [29/200], Validation Loss: 0.0774
Epoch [30/200], Average Training Loss: 0.0538
Epoch [30/200], Validation Loss: 0.0763
Epoch [31/200], Average Training Loss: 0.0509
Epoch [31/200], Validation Loss: 0.0740
Epoch [32/200], Average Training Loss: 0.0498
Epoch [32/200], Validation Loss: 0.0827
Epoch [33/200], Average Training Loss: 0.0466
Epoch [33/200], Validation Loss: 0.0802
Epoch [34/200], Average Training Loss: 0.0444
Epoch [34/200], Validation Loss: 0.0719
Epoch [35/200], Average Training Loss: 0.0471
Epoch [35/200], Validation Loss: 0.0817
Epoch [36/200], Average Training Loss: 0.0432
Epoch [36/200], Validation Loss: 0.0728
Epoch [37/200], Average Training Loss: 0.0417
Epoch [37/200], Validation Loss: 0.0751
Epoch [38/200], Average Training Loss: 0.0390
Epoch [38/200], Validation Loss: 0.0710
Epoch [39/200], Average Training Loss: 0.0395
Epoch [39/200], Validation Loss: 0.0734
Epoch [40/200], Average Training Loss: 0.0372
Epoch [40/200], Validation Loss: 0.0718
Epoch [41/200], Average Training Loss: 0.0353
Epoch [41/200], Validation Loss: 0.0721
Epoch [42/200], Average Training Loss: 0.0334
Epoch [42/200], Validation Loss: 0.0748
Epoch [43/200], Average Training Loss: 0.0334
Epoch [43/200], Validation Loss: 0.0678
Epoch [44/200], Average Training Loss: 0.0320
Epoch [44/200], Validation Loss: 0.0740
Epoch [45/200], Average Training Loss: 0.0317
Epoch [45/200], Validation Loss: 0.0667
Epoch [46/200], Average Training Loss: 0.0296
Epoch [46/200], Validation Loss: 0.0717
Epoch [47/200], Average Training Loss: 0.0279
Epoch [47/200], Validation Loss: 0.0675
Epoch [48/200], Average Training Loss: 0.0284
Epoch [48/200], Validation Loss: 0.0682
Epoch [49/200], Average Training Loss: 0.0264
Epoch [49/200], Validation Loss: 0.0679
Epoch [50/200], Average Training Loss: 0.0251
Epoch [50/200], Validation Loss: 0.0709
Epoch [51/200], Average Training Loss: 0.0260
Epoch [51/200], Validation Loss: 0.0670
Epoch [52/200], Average Training Loss: 0.0250
Epoch [52/200], Validation Loss: 0.0677
Epoch [53/200], Average Training Loss: 0.0239
Epoch [53/200], Validation Loss: 0.0673
Epoch [54/200], Average Training Loss: 0.0231
Epoch [54/200], Validation Loss: 0.0686
Epoch [55/200], Average Training Loss: 0.0224
Epoch [55/200], Validation Loss: 0.0662
Epoch [56/200], Average Training Loss: 0.0223
Epoch [56/200], Validation Loss: 0.0650
Epoch [57/200], Average Training Loss: 0.0218
Epoch [57/200], Validation Loss: 0.0664
Epoch [58/200], Average Training Loss: 0.0203
Epoch [58/200], Validation Loss: 0.0670
Epoch [59/200], Average Training Loss: 0.0202
Epoch [59/200], Validation Loss: 0.0674
Epoch [60/200], Average Training Loss: 0.0197
Epoch [60/200], Validation Loss: 0.0655
Epoch [61/200], Average Training Loss: 0.0193
Epoch [61/200], Validation Loss: 0.0660
Epoch [62/200], Average Training Loss: 0.0182
Epoch [62/200], Validation Loss: 0.0636
Epoch [63/200], Average Training Loss: 0.0182
Epoch [63/200], Validation Loss: 0.0652
Epoch [64/200], Average Training Loss: 0.0181
Epoch [64/200], Validation Loss: 0.0667
Epoch [65/200], Average Training Loss: 0.0177
Epoch [65/200], Validation Loss: 0.0659
Epoch [66/200], Average Training Loss: 0.0170
Epoch [66/200], Validation Loss: 0.0643
Epoch [67/200], Average Training Loss: 0.0166
Epoch [67/200], Validation Loss: 0.0653
Epoch [68/200], Average Training Loss: 0.0168
Epoch [68/200], Validation Loss: 0.0666
Epoch [69/200], Average Training Loss: 0.0161
Epoch [69/200], Validation Loss: 0.0640
Epoch [70/200], Average Training Loss: 0.0159
Epoch [70/200], Validation Loss: 0.0651
Epoch [71/200], Average Training Loss: 0.0153
Epoch [71/200], Validation Loss: 0.0648
Epoch [72/200], Average Training Loss: 0.0151
Epoch [72/200], Validation Loss: 0.0629
Epoch [73/200], Average Training Loss: 0.0147
Epoch [73/200], Validation Loss: 0.0650
Epoch [74/200], Average Training Loss: 0.0147
Epoch [74/200], Validation Loss: 0.0648
Epoch [75/200], Average Training Loss: 0.0146
Epoch [75/200], Validation Loss: 0.0627
Epoch [76/200], Average Training Loss: 0.0145
Epoch [76/200], Validation Loss: 0.0620
Epoch [77/200], Average Training Loss: 0.0141
Epoch [77/200], Validation Loss: 0.0641
Epoch [78/200], Average Training Loss: 0.0142
Epoch [78/200], Validation Loss: 0.0650
Epoch [79/200], Average Training Loss: 0.0141
Epoch [79/200], Validation Loss: 0.0638
Epoch [80/200], Average Training Loss: 0.0141
Epoch [80/200], Validation Loss: 0.0638
Epoch [81/200], Average Training Loss: 0.0136
Epoch [81/200], Validation Loss: 0.0622
Epoch [82/200], Average Training Loss: 0.0131
Epoch [82/200], Validation Loss: 0.0630
Epoch [83/200], Average Training Loss: 0.0129
Epoch [83/200], Validation Loss: 0.0634
Epoch [84/200], Average Training Loss: 0.0123
Epoch [84/200], Validation Loss: 0.0646
Epoch [85/200], Average Training Loss: 0.0127
Epoch [85/200], Validation Loss: 0.0628
Epoch [86/200], Average Training Loss: 0.0131
Epoch [86/200], Validation Loss: 0.0621
Epoch [87/200], Average Training Loss: 0.0122
Epoch [87/200], Validation Loss: 0.0644
Epoch [88/200], Average Training Loss: 0.0124
Epoch [88/200], Validation Loss: 0.0653
Epoch [89/200], Average Training Loss: 0.0122
Epoch [89/200], Validation Loss: 0.0652
Epoch [90/200], Average Training Loss: 0.0126
Epoch [90/200], Validation Loss: 0.0633
Epoch [91/200], Average Training Loss: 0.0122
Epoch [91/200], Validation Loss: 0.0660
Epoch [92/200], Average Training Loss: 0.0123
Epoch [92/200], Validation Loss: 0.0631
Epoch [93/200], Average Training Loss: 0.0118
Epoch [93/200], Validation Loss: 0.0627
Epoch [94/200], Average Training Loss: 0.0119
Epoch [94/200], Validation Loss: 0.0661
Epoch [95/200], Average Training Loss: 0.0121
Epoch [95/200], Validation Loss: 0.0639
Epoch [96/200], Average Training Loss: 0.0119
Epoch [96/200], Validation Loss: 0.0646
Early stopping at epoch 96
Finished Training
Training with batch_size=32 and learning_rate=0.001
Epoch [1/200], Average Training Loss: 0.2514
Epoch [1/200], Validation Loss: 0.2440
Epoch [2/200], Average Training Loss: 0.1910
Epoch [2/200], Validation Loss: 0.1385
Epoch [3/200], Average Training Loss: 0.1699
Epoch [3/200], Validation Loss: 0.1265
Epoch [4/200], Average Training Loss: 0.1656
Epoch [4/200], Validation Loss: 0.1403
Epoch [5/200], Average Training Loss: 0.1605
Epoch [5/200], Validation Loss: 0.1190
Epoch [6/200], Average Training Loss: 0.1549
Epoch [6/200], Validation Loss: 0.1113
Epoch [7/200], Average Training Loss: 0.1542
Epoch [7/200], Validation Loss: 0.1111
Epoch [8/200], Average Training Loss: 0.1459
Epoch [8/200], Validation Loss: 0.1067
Epoch [9/200], Average Training Loss: 0.1422
Epoch [9/200], Validation Loss: 0.1135
Epoch [10/200], Average Training Loss: 0.1435
Epoch [10/200], Validation Loss: 0.1018
Epoch [11/200], Average Training Loss: 0.1357
Epoch [11/200], Validation Loss: 0.1042
Epoch [12/200], Average Training Loss: 0.1341
Epoch [12/200], Validation Loss: 0.1024
Epoch [13/200], Average Training Loss: 0.1310
Epoch [13/200], Validation Loss: 0.1019
Epoch [14/200], Average Training Loss: 0.1216
Epoch [14/200], Validation Loss: 0.0961
Epoch [15/200], Average Training Loss: 0.1156
Epoch [15/200], Validation Loss: 0.0973
Epoch [16/200], Average Training Loss: 0.1105
Epoch [16/200], Validation Loss: 0.0943
Epoch [17/200], Average Training Loss: 0.1026
Epoch [17/200], Validation Loss: 0.0931
Epoch [18/200], Average Training Loss: 0.0992
Epoch [18/200], Validation Loss: 0.0909
Epoch [19/200], Average Training Loss: 0.0924
Epoch [19/200], Validation Loss: 0.0902
Epoch [20/200], Average Training Loss: 0.0938
Epoch [20/200], Validation Loss: 0.0899
Epoch [21/200], Average Training Loss: 0.0881
Epoch [21/200], Validation Loss: 0.0921
Epoch [22/200], Average Training Loss: 0.0827
Epoch [22/200], Validation Loss: 0.0854
Epoch [23/200], Average Training Loss: 0.0792
Epoch [23/200], Validation Loss: 0.0893
Epoch [24/200], Average Training Loss: 0.0783
Epoch [24/200], Validation Loss: 0.0840
Epoch [25/200], Average Training Loss: 0.0727
Epoch [25/200], Validation Loss: 0.0875
Epoch [26/200], Average Training Loss: 0.0701
Epoch [26/200], Validation Loss: 0.0857
Epoch [27/200], Average Training Loss: 0.0690
Epoch [27/200], Validation Loss: 0.0895
Epoch [28/200], Average Training Loss: 0.0662
Epoch [28/200], Validation Loss: 0.0924
Epoch [29/200], Average Training Loss: 0.0635
Epoch [29/200], Validation Loss: 0.0904
Epoch [30/200], Average Training Loss: 0.0621
Epoch [30/200], Validation Loss: 0.0864
Epoch [31/200], Average Training Loss: 0.0568
Epoch [31/200], Validation Loss: 0.0842
Epoch [32/200], Average Training Loss: 0.0558
Epoch [32/200], Validation Loss: 0.0855
Epoch [33/200], Average Training Loss: 0.0537
Epoch [33/200], Validation Loss: 0.0840
Epoch [34/200], Average Training Loss: 0.0520
Epoch [34/200], Validation Loss: 0.0877
Epoch [35/200], Average Training Loss: 0.0491
Epoch [35/200], Validation Loss: 0.0811
Epoch [36/200], Average Training Loss: 0.0477
Epoch [36/200], Validation Loss: 0.0909
Epoch [37/200], Average Training Loss: 0.0483
Epoch [37/200], Validation Loss: 0.0811
Epoch [38/200], Average Training Loss: 0.0454
Epoch [38/200], Validation Loss: 0.0800
Epoch [39/200], Average Training Loss: 0.0443
Epoch [39/200], Validation Loss: 0.0847
Epoch [40/200], Average Training Loss: 0.0430
Epoch [40/200], Validation Loss: 0.0817
Epoch [41/200], Average Training Loss: 0.0390
Epoch [41/200], Validation Loss: 0.0820
Epoch [42/200], Average Training Loss: 0.0380
Epoch [42/200], Validation Loss: 0.0808
Epoch [43/200], Average Training Loss: 0.0362
Epoch [43/200], Validation Loss: 0.0818
Epoch [44/200], Average Training Loss: 0.0364
Epoch [44/200], Validation Loss: 0.0781
Epoch [45/200], Average Training Loss: 0.0377
Epoch [45/200], Validation Loss: 0.0796
Epoch [46/200], Average Training Loss: 0.0342
Epoch [46/200], Validation Loss: 0.0783
Epoch [47/200], Average Training Loss: 0.0324
Epoch [47/200], Validation Loss: 0.0798
Epoch [48/200], Average Training Loss: 0.0319
Epoch [48/200], Validation Loss: 0.0821
Epoch [49/200], Average Training Loss: 0.0307
Epoch [49/200], Validation Loss: 0.0784
Epoch [50/200], Average Training Loss: 0.0291
Epoch [50/200], Validation Loss: 0.0786
Epoch [51/200], Average Training Loss: 0.0285
Epoch [51/200], Validation Loss: 0.0760
Epoch [52/200], Average Training Loss: 0.0293
Epoch [52/200], Validation Loss: 0.0776
Epoch [53/200], Average Training Loss: 0.0283
Epoch [53/200], Validation Loss: 0.0817
Epoch [54/200], Average Training Loss: 0.0267
Epoch [54/200], Validation Loss: 0.0775
Epoch [55/200], Average Training Loss: 0.0248
Epoch [55/200], Validation Loss: 0.0746
Epoch [56/200], Average Training Loss: 0.0238
Epoch [56/200], Validation Loss: 0.0744
Epoch [57/200], Average Training Loss: 0.0229
Epoch [57/200], Validation Loss: 0.0747
Epoch [58/200], Average Training Loss: 0.0223
Epoch [58/200], Validation Loss: 0.0726
Epoch [59/200], Average Training Loss: 0.0223
Epoch [59/200], Validation Loss: 0.0743
Epoch [60/200], Average Training Loss: 0.0225
Epoch [60/200], Validation Loss: 0.0742
Epoch [61/200], Average Training Loss: 0.0220
Epoch [61/200], Validation Loss: 0.0808
Epoch [62/200], Average Training Loss: 0.0213
Epoch [62/200], Validation Loss: 0.0749
Epoch [63/200], Average Training Loss: 0.0202
Epoch [63/200], Validation Loss: 0.0730
Epoch [64/200], Average Training Loss: 0.0193
Epoch [64/200], Validation Loss: 0.0733
Epoch [65/200], Average Training Loss: 0.0193
Epoch [65/200], Validation Loss: 0.0729
Epoch [66/200], Average Training Loss: 0.0187
Epoch [66/200], Validation Loss: 0.0755
Epoch [67/200], Average Training Loss: 0.0191
Epoch [67/200], Validation Loss: 0.0741
Epoch [68/200], Average Training Loss: 0.0188
Epoch [68/200], Validation Loss: 0.0705
Epoch [69/200], Average Training Loss: 0.0178
Epoch [69/200], Validation Loss: 0.0736
Epoch [70/200], Average Training Loss: 0.0165
Epoch [70/200], Validation Loss: 0.0739
Epoch [71/200], Average Training Loss: 0.0166
Epoch [71/200], Validation Loss: 0.0727
Epoch [72/200], Average Training Loss: 0.0175
Epoch [72/200], Validation Loss: 0.0733
Epoch [73/200], Average Training Loss: 0.0162
Epoch [73/200], Validation Loss: 0.0721
Epoch [74/200], Average Training Loss: 0.0162
Epoch [74/200], Validation Loss: 0.0706
Epoch [75/200], Average Training Loss: 0.0162
Epoch [75/200], Validation Loss: 0.0796
Epoch [76/200], Average Training Loss: 0.0160
Epoch [76/200], Validation Loss: 0.0722
Epoch [77/200], Average Training Loss: 0.0154
Epoch [77/200], Validation Loss: 0.0724
Epoch [78/200], Average Training Loss: 0.0149
Epoch [78/200], Validation Loss: 0.0746
Epoch [79/200], Average Training Loss: 0.0141
Epoch [79/200], Validation Loss: 0.0717
Epoch [80/200], Average Training Loss: 0.0146
Epoch [80/200], Validation Loss: 0.0726
Epoch [81/200], Average Training Loss: 0.0149
Epoch [81/200], Validation Loss: 0.0726
Epoch [82/200], Average Training Loss: 0.0142
Epoch [82/200], Validation Loss: 0.0719
Epoch [83/200], Average Training Loss: 0.0141
Epoch [83/200], Validation Loss: 0.0726
Epoch [84/200], Average Training Loss: 0.0136
Epoch [84/200], Validation Loss: 0.0732
Epoch [85/200], Average Training Loss: 0.0137
Epoch [85/200], Validation Loss: 0.0717
Epoch [86/200], Average Training Loss: 0.0126
Epoch [86/200], Validation Loss: 0.0722
Epoch [87/200], Average Training Loss: 0.0128
Epoch [87/200], Validation Loss: 0.0711
Epoch [88/200], Average Training Loss: 0.0123
Epoch [88/200], Validation Loss: 0.0725
Early stopping at epoch 88
Finished Training
Training with batch_size=16 and learning_rate=1e-05
Epoch [1/200], Average Training Loss: 0.3146
Epoch [1/200], Validation Loss: 0.2597
Epoch [2/200], Average Training Loss: 0.2212
Epoch [2/200], Validation Loss: 0.1784
Epoch [3/200], Average Training Loss: 0.1937
Epoch [3/200], Validation Loss: 0.1537
Epoch [4/200], Average Training Loss: 0.1800
Epoch [4/200], Validation Loss: 0.1390
Epoch [5/200], Average Training Loss: 0.1719
Epoch [5/200], Validation Loss: 0.1313
Epoch [6/200], Average Training Loss: 0.1690
Epoch [6/200], Validation Loss: 0.1275
Epoch [7/200], Average Training Loss: 0.1636
Epoch [7/200], Validation Loss: 0.1203
Epoch [8/200], Average Training Loss: 0.1613
Epoch [8/200], Validation Loss: 0.1224
Epoch [9/200], Average Training Loss: 0.1539
Epoch [9/200], Validation Loss: 0.1198
Epoch [10/200], Average Training Loss: 0.1474
Epoch [10/200], Validation Loss: 0.1129
Epoch [11/200], Average Training Loss: 0.1450
Epoch [11/200], Validation Loss: 0.1105
Epoch [12/200], Average Training Loss: 0.1436
Epoch [12/200], Validation Loss: 0.1095
Epoch [13/200], Average Training Loss: 0.1415
Epoch [13/200], Validation Loss: 0.1182
Epoch [14/200], Average Training Loss: 0.1407
Epoch [14/200], Validation Loss: 0.1050
Epoch [15/200], Average Training Loss: 0.1356
Epoch [15/200], Validation Loss: 0.1146
Epoch [16/200], Average Training Loss: 0.1298
Epoch [16/200], Validation Loss: 0.1136
Epoch [17/200], Average Training Loss: 0.1276
Epoch [17/200], Validation Loss: 0.1049
Epoch [18/200], Average Training Loss: 0.1282
Epoch [18/200], Validation Loss: 0.1135
Epoch [19/200], Average Training Loss: 0.1232
Epoch [19/200], Validation Loss: 0.0996
Epoch [20/200], Average Training Loss: 0.1177
Epoch [20/200], Validation Loss: 0.0985
Epoch [21/200], Average Training Loss: 0.1174
Epoch [21/200], Validation Loss: 0.0968
Epoch [22/200], Average Training Loss: 0.1146
Epoch [22/200], Validation Loss: 0.1040
Epoch [23/200], Average Training Loss: 0.1118
Epoch [23/200], Validation Loss: 0.0953
Epoch [24/200], Average Training Loss: 0.1079
Epoch [24/200], Validation Loss: 0.1008
Epoch [25/200], Average Training Loss: 0.1059
Epoch [25/200], Validation Loss: 0.0986
Epoch [26/200], Average Training Loss: 0.1005
Epoch [26/200], Validation Loss: 0.0953
Epoch [27/200], Average Training Loss: 0.1012
Epoch [27/200], Validation Loss: 0.0973
Epoch [28/200], Average Training Loss: 0.1007
Epoch [28/200], Validation Loss: 0.0936
Epoch [29/200], Average Training Loss: 0.0963
Epoch [29/200], Validation Loss: 0.0943
Epoch [30/200], Average Training Loss: 0.0933
Epoch [30/200], Validation Loss: 0.0974
Epoch [31/200], Average Training Loss: 0.0934
Epoch [31/200], Validation Loss: 0.1005
Epoch [32/200], Average Training Loss: 0.0903
Epoch [32/200], Validation Loss: 0.0980
Epoch [33/200], Average Training Loss: 0.0893
Epoch [33/200], Validation Loss: 0.1039
Epoch [34/200], Average Training Loss: 0.0875
Epoch [34/200], Validation Loss: 0.0920
Epoch [35/200], Average Training Loss: 0.0909
Epoch [35/200], Validation Loss: 0.1016
Epoch [36/200], Average Training Loss: 0.0861
Epoch [36/200], Validation Loss: 0.0918
Epoch [37/200], Average Training Loss: 0.0849
Epoch [37/200], Validation Loss: 0.1013
Epoch [38/200], Average Training Loss: 0.0835
Epoch [38/200], Validation Loss: 0.0899
Epoch [39/200], Average Training Loss: 0.0818
Epoch [39/200], Validation Loss: 0.1025
Epoch [40/200], Average Training Loss: 0.0814
Epoch [40/200], Validation Loss: 0.0957
Epoch [41/200], Average Training Loss: 0.0802
Epoch [41/200], Validation Loss: 0.1014
Epoch [42/200], Average Training Loss: 0.0805
Epoch [42/200], Validation Loss: 0.0984
Epoch [43/200], Average Training Loss: 0.0781
Epoch [43/200], Validation Loss: 0.0951
Epoch [44/200], Average Training Loss: 0.0759
Epoch [44/200], Validation Loss: 0.0895
Epoch [45/200], Average Training Loss: 0.0771
Epoch [45/200], Validation Loss: 0.0912
Epoch [46/200], Average Training Loss: 0.0752
Epoch [46/200], Validation Loss: 0.0981
Epoch [47/200], Average Training Loss: 0.0734
Epoch [47/200], Validation Loss: 0.0976
Epoch [48/200], Average Training Loss: 0.0729
Epoch [48/200], Validation Loss: 0.0959
Epoch [49/200], Average Training Loss: 0.0713
Epoch [49/200], Validation Loss: 0.0943
Epoch [50/200], Average Training Loss: 0.0718
Epoch [50/200], Validation Loss: 0.0924
Epoch [51/200], Average Training Loss: 0.0689
Epoch [51/200], Validation Loss: 0.0947
Epoch [52/200], Average Training Loss: 0.0684
Epoch [52/200], Validation Loss: 0.0983
Epoch [53/200], Average Training Loss: 0.0692
Epoch [53/200], Validation Loss: 0.0968
Epoch [54/200], Average Training Loss: 0.0654
Epoch [54/200], Validation Loss: 0.0978
Epoch [55/200], Average Training Loss: 0.0642
Epoch [55/200], Validation Loss: 0.0984
Epoch [56/200], Average Training Loss: 0.0654
Epoch [56/200], Validation Loss: 0.0939
Epoch [57/200], Average Training Loss: 0.0645
Epoch [57/200], Validation Loss: 0.0995
Epoch [58/200], Average Training Loss: 0.0629
Epoch [58/200], Validation Loss: 0.0967
Epoch [59/200], Average Training Loss: 0.0644
Epoch [59/200], Validation Loss: 0.0919
Epoch [60/200], Average Training Loss: 0.0609
Epoch [60/200], Validation Loss: 0.0916
Epoch [61/200], Average Training Loss: 0.0606
Epoch [61/200], Validation Loss: 0.0969
Epoch [62/200], Average Training Loss: 0.0610
Epoch [62/200], Validation Loss: 0.0922
Epoch [63/200], Average Training Loss: 0.0612
Epoch [63/200], Validation Loss: 0.1029
Epoch [64/200], Average Training Loss: 0.0595
Epoch [64/200], Validation Loss: 0.0934
Early stopping at epoch 64
Finished Training
Training with batch_size=16 and learning_rate=0.0001
Epoch [1/200], Average Training Loss: 0.2225
Epoch [1/200], Validation Loss: 0.1555
Epoch [2/200], Average Training Loss: 0.1813
Epoch [2/200], Validation Loss: 0.1521
Epoch [3/200], Average Training Loss: 0.1713
Epoch [3/200], Validation Loss: 0.1166
Epoch [4/200], Average Training Loss: 0.1574
Epoch [4/200], Validation Loss: 0.1094
Epoch [5/200], Average Training Loss: 0.1480
Epoch [5/200], Validation Loss: 0.1063
Epoch [6/200], Average Training Loss: 0.1440
Epoch [6/200], Validation Loss: 0.1234
Epoch [7/200], Average Training Loss: 0.1391
Epoch [7/200], Validation Loss: 0.0998
Epoch [8/200], Average Training Loss: 0.1336
Epoch [8/200], Validation Loss: 0.0965
Epoch [9/200], Average Training Loss: 0.1255
Epoch [9/200], Validation Loss: 0.1070
Epoch [10/200], Average Training Loss: 0.1173
Epoch [10/200], Validation Loss: 0.0957
Epoch [11/200], Average Training Loss: 0.1098
Epoch [11/200], Validation Loss: 0.0920
Epoch [12/200], Average Training Loss: 0.1039
Epoch [12/200], Validation Loss: 0.0825
Epoch [13/200], Average Training Loss: 0.1010
Epoch [13/200], Validation Loss: 0.0874
Epoch [14/200], Average Training Loss: 0.0936
Epoch [14/200], Validation Loss: 0.0847
Epoch [15/200], Average Training Loss: 0.0876
Epoch [15/200], Validation Loss: 0.0811
Epoch [16/200], Average Training Loss: 0.0834
Epoch [16/200], Validation Loss: 0.0891
Epoch [17/200], Average Training Loss: 0.0821
Epoch [17/200], Validation Loss: 0.0825
Epoch [18/200], Average Training Loss: 0.0743
Epoch [18/200], Validation Loss: 0.0835
Epoch [19/200], Average Training Loss: 0.0718
Epoch [19/200], Validation Loss: 0.0842
Epoch [20/200], Average Training Loss: 0.0682
Epoch [20/200], Validation Loss: 0.0828
Epoch [21/200], Average Training Loss: 0.0674
Epoch [21/200], Validation Loss: 0.0869
Epoch [22/200], Average Training Loss: 0.0653
Epoch [22/200], Validation Loss: 0.0771
Epoch [23/200], Average Training Loss: 0.0591
Epoch [23/200], Validation Loss: 0.0792
Epoch [24/200], Average Training Loss: 0.0579
Epoch [24/200], Validation Loss: 0.0793
Epoch [25/200], Average Training Loss: 0.0535
Epoch [25/200], Validation Loss: 0.0825
Epoch [26/200], Average Training Loss: 0.0515
Epoch [26/200], Validation Loss: 0.0799
Epoch [27/200], Average Training Loss: 0.0502
Epoch [27/200], Validation Loss: 0.0790
Epoch [28/200], Average Training Loss: 0.0477
Epoch [28/200], Validation Loss: 0.0822
Epoch [29/200], Average Training Loss: 0.0499
Epoch [29/200], Validation Loss: 0.0759
Epoch [30/200], Average Training Loss: 0.0448
Epoch [30/200], Validation Loss: 0.0823
Epoch [31/200], Average Training Loss: 0.0435
Epoch [31/200], Validation Loss: 0.0745
Epoch [32/200], Average Training Loss: 0.0413
Epoch [32/200], Validation Loss: 0.0718
Epoch [33/200], Average Training Loss: 0.0393
Epoch [33/200], Validation Loss: 0.0734
Epoch [34/200], Average Training Loss: 0.0368
Epoch [34/200], Validation Loss: 0.0735
Epoch [35/200], Average Training Loss: 0.0369
Epoch [35/200], Validation Loss: 0.0734
Epoch [36/200], Average Training Loss: 0.0332
Epoch [36/200], Validation Loss: 0.0794
Epoch [37/200], Average Training Loss: 0.0327
Epoch [37/200], Validation Loss: 0.0698
Epoch [38/200], Average Training Loss: 0.0336
Epoch [38/200], Validation Loss: 0.0733
Epoch [39/200], Average Training Loss: 0.0303
Epoch [39/200], Validation Loss: 0.0690
Epoch [40/200], Average Training Loss: 0.0286
Epoch [40/200], Validation Loss: 0.0693
Epoch [41/200], Average Training Loss: 0.0267
Epoch [41/200], Validation Loss: 0.0695
Epoch [42/200], Average Training Loss: 0.0264
Epoch [42/200], Validation Loss: 0.0745
Epoch [43/200], Average Training Loss: 0.0254
Epoch [43/200], Validation Loss: 0.0709
Epoch [44/200], Average Training Loss: 0.0253
Epoch [44/200], Validation Loss: 0.0692
Epoch [45/200], Average Training Loss: 0.0247
Epoch [45/200], Validation Loss: 0.0751
Epoch [46/200], Average Training Loss: 0.0249
Epoch [46/200], Validation Loss: 0.0665
Epoch [47/200], Average Training Loss: 0.0225
Epoch [47/200], Validation Loss: 0.0670
Epoch [48/200], Average Training Loss: 0.0229
Epoch [48/200], Validation Loss: 0.0702
Epoch [49/200], Average Training Loss: 0.0226
Epoch [49/200], Validation Loss: 0.0731
Epoch [50/200], Average Training Loss: 0.0211
Epoch [50/200], Validation Loss: 0.0671
Epoch [51/200], Average Training Loss: 0.0201
Epoch [51/200], Validation Loss: 0.0694
Epoch [52/200], Average Training Loss: 0.0195
Epoch [52/200], Validation Loss: 0.0669
Epoch [53/200], Average Training Loss: 0.0204
Epoch [53/200], Validation Loss: 0.0688
Epoch [54/200], Average Training Loss: 0.0191
Epoch [54/200], Validation Loss: 0.0671
Epoch [55/200], Average Training Loss: 0.0192
Epoch [55/200], Validation Loss: 0.0652
Epoch [56/200], Average Training Loss: 0.0179
Epoch [56/200], Validation Loss: 0.0675
Epoch [57/200], Average Training Loss: 0.0180
Epoch [57/200], Validation Loss: 0.0660
Epoch [58/200], Average Training Loss: 0.0173
Epoch [58/200], Validation Loss: 0.0676
Epoch [59/200], Average Training Loss: 0.0171
Epoch [59/200], Validation Loss: 0.0638
Epoch [60/200], Average Training Loss: 0.0171
Epoch [60/200], Validation Loss: 0.0680
Epoch [61/200], Average Training Loss: 0.0166
Epoch [61/200], Validation Loss: 0.0640
Epoch [62/200], Average Training Loss: 0.0162
Epoch [62/200], Validation Loss: 0.0663
Epoch [63/200], Average Training Loss: 0.0152
Epoch [63/200], Validation Loss: 0.0659
Epoch [64/200], Average Training Loss: 0.0154
Epoch [64/200], Validation Loss: 0.0657
Epoch [65/200], Average Training Loss: 0.0159
Epoch [65/200], Validation Loss: 0.0666
Epoch [66/200], Average Training Loss: 0.0161
Epoch [66/200], Validation Loss: 0.0669
Epoch [67/200], Average Training Loss: 0.0162
Epoch [67/200], Validation Loss: 0.0664
Epoch [68/200], Average Training Loss: 0.0147
Epoch [68/200], Validation Loss: 0.0672
Epoch [69/200], Average Training Loss: 0.0145
Epoch [69/200], Validation Loss: 0.0690
Epoch [70/200], Average Training Loss: 0.0145
Epoch [70/200], Validation Loss: 0.0647
Epoch [71/200], Average Training Loss: 0.0138
Epoch [71/200], Validation Loss: 0.0655
Epoch [72/200], Average Training Loss: 0.0135
Epoch [72/200], Validation Loss: 0.0691
Epoch [73/200], Average Training Loss: 0.0135
Epoch [73/200], Validation Loss: 0.0660
Epoch [74/200], Average Training Loss: 0.0126
Epoch [74/200], Validation Loss: 0.0660
Epoch [75/200], Average Training Loss: 0.0124
Epoch [75/200], Validation Loss: 0.0649
Epoch [76/200], Average Training Loss: 0.0130
Epoch [76/200], Validation Loss: 0.0649
Epoch [77/200], Average Training Loss: 0.0129
Epoch [77/200], Validation Loss: 0.0656
Epoch [78/200], Average Training Loss: 0.0122
Epoch [78/200], Validation Loss: 0.0693
Epoch [79/200], Average Training Loss: 0.0127
Epoch [79/200], Validation Loss: 0.0647
Early stopping at epoch 79
Finished Training
Training with batch_size=16 and learning_rate=0.001
Epoch [1/200], Average Training Loss: 0.2311
Epoch [1/200], Validation Loss: 0.1893
Epoch [2/200], Average Training Loss: 0.1908
Epoch [2/200], Validation Loss: 0.1481
Epoch [3/200], Average Training Loss: 0.1725
Epoch [3/200], Validation Loss: 0.1408
Epoch [4/200], Average Training Loss: 0.1658
Epoch [4/200], Validation Loss: 0.1288
Epoch [5/200], Average Training Loss: 0.1579
Epoch [5/200], Validation Loss: 0.1340
Epoch [6/200], Average Training Loss: 0.1524
Epoch [6/200], Validation Loss: 0.1071
Epoch [7/200], Average Training Loss: 0.1457
Epoch [7/200], Validation Loss: 0.1169
Epoch [8/200], Average Training Loss: 0.1422
Epoch [8/200], Validation Loss: 0.1177
Epoch [9/200], Average Training Loss: 0.1353
Epoch [9/200], Validation Loss: 0.1016
Epoch [10/200], Average Training Loss: 0.1346
Epoch [10/200], Validation Loss: 0.1021
Epoch [11/200], Average Training Loss: 0.1276
Epoch [11/200], Validation Loss: 0.0998
Epoch [12/200], Average Training Loss: 0.1221
Epoch [12/200], Validation Loss: 0.1033
Epoch [13/200], Average Training Loss: 0.1149
Epoch [13/200], Validation Loss: 0.0913
Epoch [14/200], Average Training Loss: 0.1090
Epoch [14/200], Validation Loss: 0.0956
Epoch [15/200], Average Training Loss: 0.1043
Epoch [15/200], Validation Loss: 0.0956
Epoch [16/200], Average Training Loss: 0.0987
Epoch [16/200], Validation Loss: 0.0960
Epoch [17/200], Average Training Loss: 0.0929
Epoch [17/200], Validation Loss: 0.0979
Epoch [18/200], Average Training Loss: 0.0921
Epoch [18/200], Validation Loss: 0.0915
Epoch [19/200], Average Training Loss: 0.0860
Epoch [19/200], Validation Loss: 0.1041
Epoch [20/200], Average Training Loss: 0.0811
Epoch [20/200], Validation Loss: 0.0900
Epoch [21/200], Average Training Loss: 0.0813
Epoch [21/200], Validation Loss: 0.0933
Epoch [22/200], Average Training Loss: 0.0757
Epoch [22/200], Validation Loss: 0.0958
Epoch [23/200], Average Training Loss: 0.0696
Epoch [23/200], Validation Loss: 0.0881
Epoch [24/200], Average Training Loss: 0.0682
Epoch [24/200], Validation Loss: 0.0957
Epoch [25/200], Average Training Loss: 0.0638
Epoch [25/200], Validation Loss: 0.0898
Epoch [26/200], Average Training Loss: 0.0633
Epoch [26/200], Validation Loss: 0.1004
Epoch [27/200], Average Training Loss: 0.0655
Epoch [27/200], Validation Loss: 0.0968
Epoch [28/200], Average Training Loss: 0.0629
Epoch [28/200], Validation Loss: 0.0874
Epoch [29/200], Average Training Loss: 0.0583
Epoch [29/200], Validation Loss: 0.0903
Epoch [30/200], Average Training Loss: 0.0569
Epoch [30/200], Validation Loss: 0.0927
Epoch [31/200], Average Training Loss: 0.0550
Epoch [31/200], Validation Loss: 0.0851
Epoch [32/200], Average Training Loss: 0.0513
Epoch [32/200], Validation Loss: 0.0910
Epoch [33/200], Average Training Loss: 0.0485
Epoch [33/200], Validation Loss: 0.0861
Epoch [34/200], Average Training Loss: 0.0470
Epoch [34/200], Validation Loss: 0.0849
Epoch [35/200], Average Training Loss: 0.0455
Epoch [35/200], Validation Loss: 0.0916
Epoch [36/200], Average Training Loss: 0.0442
Epoch [36/200], Validation Loss: 0.0841
Epoch [37/200], Average Training Loss: 0.0443
Epoch [37/200], Validation Loss: 0.0816
Epoch [38/200], Average Training Loss: 0.0410
Epoch [38/200], Validation Loss: 0.0891
Epoch [39/200], Average Training Loss: 0.0404
Epoch [39/200], Validation Loss: 0.0886
Epoch [40/200], Average Training Loss: 0.0393
Epoch [40/200], Validation Loss: 0.0863
Epoch [41/200], Average Training Loss: 0.0393
Epoch [41/200], Validation Loss: 0.0827
Epoch [42/200], Average Training Loss: 0.0348
Epoch [42/200], Validation Loss: 0.0893
Epoch [43/200], Average Training Loss: 0.0350
Epoch [43/200], Validation Loss: 0.0826
Epoch [44/200], Average Training Loss: 0.0340
Epoch [44/200], Validation Loss: 0.0834
Epoch [45/200], Average Training Loss: 0.0329
Epoch [45/200], Validation Loss: 0.0881
Epoch [46/200], Average Training Loss: 0.0299
Epoch [46/200], Validation Loss: 0.0819
Epoch [47/200], Average Training Loss: 0.0299
Epoch [47/200], Validation Loss: 0.0805
Epoch [48/200], Average Training Loss: 0.0287
Epoch [48/200], Validation Loss: 0.0890
Epoch [49/200], Average Training Loss: 0.0310
Epoch [49/200], Validation Loss: 0.0843
Epoch [50/200], Average Training Loss: 0.0290
Epoch [50/200], Validation Loss: 0.0807
Epoch [51/200], Average Training Loss: 0.0290
Epoch [51/200], Validation Loss: 0.0799
Epoch [52/200], Average Training Loss: 0.0277
Epoch [52/200], Validation Loss: 0.0802
Epoch [53/200], Average Training Loss: 0.0248
Epoch [53/200], Validation Loss: 0.0864
Epoch [54/200], Average Training Loss: 0.0254
Epoch [54/200], Validation Loss: 0.0829
Epoch [55/200], Average Training Loss: 0.0236
Epoch [55/200], Validation Loss: 0.0813
Epoch [56/200], Average Training Loss: 0.0226
Epoch [56/200], Validation Loss: 0.0813
Epoch [57/200], Average Training Loss: 0.0223
Epoch [57/200], Validation Loss: 0.0821
Epoch [58/200], Average Training Loss: 0.0220
Epoch [58/200], Validation Loss: 0.0799
Epoch [59/200], Average Training Loss: 0.0211
Epoch [59/200], Validation Loss: 0.0822
Epoch [60/200], Average Training Loss: 0.0206
Epoch [60/200], Validation Loss: 0.0814
Epoch [61/200], Average Training Loss: 0.0209
Epoch [61/200], Validation Loss: 0.0848
Epoch [62/200], Average Training Loss: 0.0201
Epoch [62/200], Validation Loss: 0.0796
Epoch [63/200], Average Training Loss: 0.0208
Epoch [63/200], Validation Loss: 0.0769
Epoch [64/200], Average Training Loss: 0.0193
Epoch [64/200], Validation Loss: 0.0818
Epoch [65/200], Average Training Loss: 0.0196
Epoch [65/200], Validation Loss: 0.0773
Epoch [66/200], Average Training Loss: 0.0191
Epoch [66/200], Validation Loss: 0.0810
Epoch [67/200], Average Training Loss: 0.0182
Epoch [67/200], Validation Loss: 0.0795
Epoch [68/200], Average Training Loss: 0.0172
Epoch [68/200], Validation Loss: 0.0769
Epoch [69/200], Average Training Loss: 0.0166
Epoch [69/200], Validation Loss: 0.0735
Epoch [70/200], Average Training Loss: 0.0166
Epoch [70/200], Validation Loss: 0.0810
Epoch [71/200], Average Training Loss: 0.0170
Epoch [71/200], Validation Loss: 0.0774
Epoch [72/200], Average Training Loss: 0.0162
Epoch [72/200], Validation Loss: 0.0745
Epoch [73/200], Average Training Loss: 0.0169
Epoch [73/200], Validation Loss: 0.0759
Epoch [74/200], Average Training Loss: 0.0163
Epoch [74/200], Validation Loss: 0.0763
Epoch [75/200], Average Training Loss: 0.0155
Epoch [75/200], Validation Loss: 0.0780
Epoch [76/200], Average Training Loss: 0.0156
Epoch [76/200], Validation Loss: 0.0775
Epoch [77/200], Average Training Loss: 0.0150
Epoch [77/200], Validation Loss: 0.0769
Epoch [78/200], Average Training Loss: 0.0142
Epoch [78/200], Validation Loss: 0.0783
Epoch [79/200], Average Training Loss: 0.0146
Epoch [79/200], Validation Loss: 0.0757
Epoch [80/200], Average Training Loss: 0.0145
Epoch [80/200], Validation Loss: 0.0772
Epoch [81/200], Average Training Loss: 0.0142
Epoch [81/200], Validation Loss: 0.0744
Epoch [82/200], Average Training Loss: 0.0146
Epoch [82/200], Validation Loss: 0.0745
Epoch [83/200], Average Training Loss: 0.0145
Epoch [83/200], Validation Loss: 0.0742
Epoch [84/200], Average Training Loss: 0.0142
Epoch [84/200], Validation Loss: 0.0828
Epoch [85/200], Average Training Loss: 0.0138
Epoch [85/200], Validation Loss: 0.0761
Epoch [86/200], Average Training Loss: 0.0137
Epoch [86/200], Validation Loss: 0.0764
Epoch [87/200], Average Training Loss: 0.0132
Epoch [87/200], Validation Loss: 0.0757
Epoch [88/200], Average Training Loss: 0.0145
Epoch [88/200], Validation Loss: 0.0745
Epoch [89/200], Average Training Loss: 0.0137
Epoch [89/200], Validation Loss: 0.0775
Early stopping at epoch 89
Finished Training
Training with batch_size=8 and learning_rate=1e-05
Epoch [1/200], Average Training Loss: 0.2696
Epoch [1/200], Validation Loss: 0.2400
Epoch [2/200], Average Training Loss: 0.2072
Epoch [2/200], Validation Loss: 0.1577
Epoch [3/200], Average Training Loss: 0.1827
Epoch [3/200], Validation Loss: 0.1435
Epoch [4/200], Average Training Loss: 0.1713
Epoch [4/200], Validation Loss: 0.1279
Epoch [5/200], Average Training Loss: 0.1653
Epoch [5/200], Validation Loss: 0.1300
Epoch [6/200], Average Training Loss: 0.1583
Epoch [6/200], Validation Loss: 0.1176
Epoch [7/200], Average Training Loss: 0.1535
Epoch [7/200], Validation Loss: 0.1159
Epoch [8/200], Average Training Loss: 0.1469
Epoch [8/200], Validation Loss: 0.1096
Epoch [9/200], Average Training Loss: 0.1432
Epoch [9/200], Validation Loss: 0.1100
Epoch [10/200], Average Training Loss: 0.1361
Epoch [10/200], Validation Loss: 0.1030
Epoch [11/200], Average Training Loss: 0.1341
Epoch [11/200], Validation Loss: 0.1089
Epoch [12/200], Average Training Loss: 0.1268
Epoch [12/200], Validation Loss: 0.1034
Epoch [13/200], Average Training Loss: 0.1246
Epoch [13/200], Validation Loss: 0.1130
Epoch [14/200], Average Training Loss: 0.1178
Epoch [14/200], Validation Loss: 0.1077
Epoch [15/200], Average Training Loss: 0.1144
Epoch [15/200], Validation Loss: 0.0970
Epoch [16/200], Average Training Loss: 0.1097
Epoch [16/200], Validation Loss: 0.1013
Epoch [17/200], Average Training Loss: 0.1064
Epoch [17/200], Validation Loss: 0.0992
Epoch [18/200], Average Training Loss: 0.1080
Epoch [18/200], Validation Loss: 0.0938
Epoch [19/200], Average Training Loss: 0.1008
Epoch [19/200], Validation Loss: 0.0950
Epoch [20/200], Average Training Loss: 0.0992
Epoch [20/200], Validation Loss: 0.0936
Epoch [21/200], Average Training Loss: 0.0947
Epoch [21/200], Validation Loss: 0.1000
Epoch [22/200], Average Training Loss: 0.0930
Epoch [22/200], Validation Loss: 0.0932
Epoch [23/200], Average Training Loss: 0.0908
Epoch [23/200], Validation Loss: 0.0926
Epoch [24/200], Average Training Loss: 0.0886
Epoch [24/200], Validation Loss: 0.0888
Epoch [25/200], Average Training Loss: 0.0865
Epoch [25/200], Validation Loss: 0.0953
Epoch [26/200], Average Training Loss: 0.0840
Epoch [26/200], Validation Loss: 0.0908
Epoch [27/200], Average Training Loss: 0.0838
Epoch [27/200], Validation Loss: 0.0902
Epoch [28/200], Average Training Loss: 0.0798
Epoch [28/200], Validation Loss: 0.0894
Epoch [29/200], Average Training Loss: 0.0791
Epoch [29/200], Validation Loss: 0.0929
Epoch [30/200], Average Training Loss: 0.0774
Epoch [30/200], Validation Loss: 0.0955
Epoch [31/200], Average Training Loss: 0.0741
Epoch [31/200], Validation Loss: 0.0910
Epoch [32/200], Average Training Loss: 0.0747
Epoch [32/200], Validation Loss: 0.0979
Epoch [33/200], Average Training Loss: 0.0704
Epoch [33/200], Validation Loss: 0.0912
Epoch [34/200], Average Training Loss: 0.0705
Epoch [34/200], Validation Loss: 0.0919
Epoch [35/200], Average Training Loss: 0.0694
Epoch [35/200], Validation Loss: 0.0940
Epoch [36/200], Average Training Loss: 0.0705
Epoch [36/200], Validation Loss: 0.0908
Epoch [37/200], Average Training Loss: 0.0673
Epoch [37/200], Validation Loss: 0.0929
Epoch [38/200], Average Training Loss: 0.0670
Epoch [38/200], Validation Loss: 0.0951
Epoch [39/200], Average Training Loss: 0.0661
Epoch [39/200], Validation Loss: 0.0892
Epoch [40/200], Average Training Loss: 0.0646
Epoch [40/200], Validation Loss: 0.0923
Epoch [41/200], Average Training Loss: 0.0646
Epoch [41/200], Validation Loss: 0.0948
Epoch [42/200], Average Training Loss: 0.0623
Epoch [42/200], Validation Loss: 0.1018
Epoch [43/200], Average Training Loss: 0.0607
Epoch [43/200], Validation Loss: 0.0926
Epoch [44/200], Average Training Loss: 0.0615
Epoch [44/200], Validation Loss: 0.0985
Early stopping at epoch 44
Finished Training
Training with batch_size=8 and learning_rate=0.0001
Epoch [1/200], Average Training Loss: 0.2016
Epoch [1/200], Validation Loss: 0.1532
Epoch [2/200], Average Training Loss: 0.1708
Epoch [2/200], Validation Loss: 0.1223
Epoch [3/200], Average Training Loss: 0.1548
Epoch [3/200], Validation Loss: 0.1112
Epoch [4/200], Average Training Loss: 0.1522
Epoch [4/200], Validation Loss: 0.1068
Epoch [5/200], Average Training Loss: 0.1460
Epoch [5/200], Validation Loss: 0.1097
Epoch [6/200], Average Training Loss: 0.1367
Epoch [6/200], Validation Loss: 0.1050
Epoch [7/200], Average Training Loss: 0.1310
Epoch [7/200], Validation Loss: 0.0967
Epoch [8/200], Average Training Loss: 0.1226
Epoch [8/200], Validation Loss: 0.0997
Epoch [9/200], Average Training Loss: 0.1154
Epoch [9/200], Validation Loss: 0.0928
Epoch [10/200], Average Training Loss: 0.1068
Epoch [10/200], Validation Loss: 0.0839
Epoch [11/200], Average Training Loss: 0.1002
Epoch [11/200], Validation Loss: 0.0921
Epoch [12/200], Average Training Loss: 0.0956
Epoch [12/200], Validation Loss: 0.0901
Epoch [13/200], Average Training Loss: 0.0879
Epoch [13/200], Validation Loss: 0.0821
Epoch [14/200], Average Training Loss: 0.0798
Epoch [14/200], Validation Loss: 0.0816
Epoch [15/200], Average Training Loss: 0.0815
Epoch [15/200], Validation Loss: 0.0796
Epoch [16/200], Average Training Loss: 0.0752
Epoch [16/200], Validation Loss: 0.0780
Epoch [17/200], Average Training Loss: 0.0689
Epoch [17/200], Validation Loss: 0.0784
Epoch [18/200], Average Training Loss: 0.0698
Epoch [18/200], Validation Loss: 0.0927
Epoch [19/200], Average Training Loss: 0.0646
Epoch [19/200], Validation Loss: 0.0905
Epoch [20/200], Average Training Loss: 0.0600
Epoch [20/200], Validation Loss: 0.0819
Epoch [21/200], Average Training Loss: 0.0577
Epoch [21/200], Validation Loss: 0.0751
Epoch [22/200], Average Training Loss: 0.0587
Epoch [22/200], Validation Loss: 0.0765
Epoch [23/200], Average Training Loss: 0.0533
Epoch [23/200], Validation Loss: 0.0806
Epoch [24/200], Average Training Loss: 0.0474
Epoch [24/200], Validation Loss: 0.0730
Epoch [25/200], Average Training Loss: 0.0464
Epoch [25/200], Validation Loss: 0.0742
Epoch [26/200], Average Training Loss: 0.0415
Epoch [26/200], Validation Loss: 0.0679
Epoch [27/200], Average Training Loss: 0.0426
Epoch [27/200], Validation Loss: 0.0757
Epoch [28/200], Average Training Loss: 0.0419
Epoch [28/200], Validation Loss: 0.0727
Epoch [29/200], Average Training Loss: 0.0382
Epoch [29/200], Validation Loss: 0.0714
Epoch [30/200], Average Training Loss: 0.0387
Epoch [30/200], Validation Loss: 0.0696
Epoch [31/200], Average Training Loss: 0.0376
Epoch [31/200], Validation Loss: 0.0705
Epoch [32/200], Average Training Loss: 0.0347
Epoch [32/200], Validation Loss: 0.0683
Epoch [33/200], Average Training Loss: 0.0342
Epoch [33/200], Validation Loss: 0.0725
Epoch [34/200], Average Training Loss: 0.0312
Epoch [34/200], Validation Loss: 0.0680
Epoch [35/200], Average Training Loss: 0.0307
Epoch [35/200], Validation Loss: 0.0685
Epoch [36/200], Average Training Loss: 0.0286
Epoch [36/200], Validation Loss: 0.0655
Epoch [37/200], Average Training Loss: 0.0269
Epoch [37/200], Validation Loss: 0.0714
Epoch [38/200], Average Training Loss: 0.0280
Epoch [38/200], Validation Loss: 0.0670
Epoch [39/200], Average Training Loss: 0.0273
Epoch [39/200], Validation Loss: 0.0691
Epoch [40/200], Average Training Loss: 0.0267
Epoch [40/200], Validation Loss: 0.0676
Epoch [41/200], Average Training Loss: 0.0256
Epoch [41/200], Validation Loss: 0.0696
Epoch [42/200], Average Training Loss: 0.0250
Epoch [42/200], Validation Loss: 0.0706
Epoch [43/200], Average Training Loss: 0.0233
Epoch [43/200], Validation Loss: 0.0714
Epoch [44/200], Average Training Loss: 0.0222
Epoch [44/200], Validation Loss: 0.0670
Epoch [45/200], Average Training Loss: 0.0213
Epoch [45/200], Validation Loss: 0.0666
Epoch [46/200], Average Training Loss: 0.0206
Epoch [46/200], Validation Loss: 0.0640
Epoch [47/200], Average Training Loss: 0.0212
Epoch [47/200], Validation Loss: 0.0691
Epoch [48/200], Average Training Loss: 0.0208
Epoch [48/200], Validation Loss: 0.0620
Epoch [49/200], Average Training Loss: 0.0196
Epoch [49/200], Validation Loss: 0.0676
Epoch [50/200], Average Training Loss: 0.0196
Epoch [50/200], Validation Loss: 0.0664
Epoch [51/200], Average Training Loss: 0.0180
Epoch [51/200], Validation Loss: 0.0636
Epoch [52/200], Average Training Loss: 0.0179
Epoch [52/200], Validation Loss: 0.0644
Epoch [53/200], Average Training Loss: 0.0178
Epoch [53/200], Validation Loss: 0.0647
Epoch [54/200], Average Training Loss: 0.0177
Epoch [54/200], Validation Loss: 0.0645
Epoch [55/200], Average Training Loss: 0.0167
Epoch [55/200], Validation Loss: 0.0639
Epoch [56/200], Average Training Loss: 0.0161
Epoch [56/200], Validation Loss: 0.0642
Epoch [57/200], Average Training Loss: 0.0171
Epoch [57/200], Validation Loss: 0.0607
Epoch [58/200], Average Training Loss: 0.0170
Epoch [58/200], Validation Loss: 0.0652
Epoch [59/200], Average Training Loss: 0.0161
Epoch [59/200], Validation Loss: 0.0661
Epoch [60/200], Average Training Loss: 0.0161
Epoch [60/200], Validation Loss: 0.0675
Epoch [61/200], Average Training Loss: 0.0159
Epoch [61/200], Validation Loss: 0.0652
Epoch [62/200], Average Training Loss: 0.0152
Epoch [62/200], Validation Loss: 0.0624
Epoch [63/200], Average Training Loss: 0.0147
Epoch [63/200], Validation Loss: 0.0640
Epoch [64/200], Average Training Loss: 0.0151
Epoch [64/200], Validation Loss: 0.0628
Epoch [65/200], Average Training Loss: 0.0147
Epoch [65/200], Validation Loss: 0.0635
Epoch [66/200], Average Training Loss: 0.0147
Epoch [66/200], Validation Loss: 0.0638
Epoch [67/200], Average Training Loss: 0.0140
Epoch [67/200], Validation Loss: 0.0633
Epoch [68/200], Average Training Loss: 0.0140
Epoch [68/200], Validation Loss: 0.0629
Epoch [69/200], Average Training Loss: 0.0140
Epoch [69/200], Validation Loss: 0.0624
Epoch [70/200], Average Training Loss: 0.0143
Epoch [70/200], Validation Loss: 0.0658
Epoch [71/200], Average Training Loss: 0.0135
Epoch [71/200], Validation Loss: 0.0620
Epoch [72/200], Average Training Loss: 0.0134
Epoch [72/200], Validation Loss: 0.0637
Epoch [73/200], Average Training Loss: 0.0127
Epoch [73/200], Validation Loss: 0.0642
Epoch [74/200], Average Training Loss: 0.0130
Epoch [74/200], Validation Loss: 0.0613
Epoch [75/200], Average Training Loss: 0.0124
Epoch [75/200], Validation Loss: 0.0642
Epoch [76/200], Average Training Loss: 0.0118
Epoch [76/200], Validation Loss: 0.0622
Epoch [77/200], Average Training Loss: 0.0117
Epoch [77/200], Validation Loss: 0.0627
Early stopping at epoch 77
Finished Training
Training with batch_size=8 and learning_rate=0.001
Epoch [1/200], Average Training Loss: 0.2122
Epoch [1/200], Validation Loss: 0.1883
Epoch [2/200], Average Training Loss: 0.1917
Epoch [2/200], Validation Loss: 0.1369
Epoch [3/200], Average Training Loss: 0.1701
Epoch [3/200], Validation Loss: 0.1515
Epoch [4/200], Average Training Loss: 0.1637
Epoch [4/200], Validation Loss: 0.1327
Epoch [5/200], Average Training Loss: 0.1565
Epoch [5/200], Validation Loss: 0.1118
Epoch [6/200], Average Training Loss: 0.1500
Epoch [6/200], Validation Loss: 0.1307
Epoch [7/200], Average Training Loss: 0.1449
Epoch [7/200], Validation Loss: 0.1189
Epoch [8/200], Average Training Loss: 0.1413
Epoch [8/200], Validation Loss: 0.1095
Epoch [9/200], Average Training Loss: 0.1356
Epoch [9/200], Validation Loss: 0.1032
Epoch [10/200], Average Training Loss: 0.1276
Epoch [10/200], Validation Loss: 0.1018
Epoch [11/200], Average Training Loss: 0.1284
Epoch [11/200], Validation Loss: 0.1051
Epoch [12/200], Average Training Loss: 0.1162
Epoch [12/200], Validation Loss: 0.0934
Epoch [13/200], Average Training Loss: 0.1096
Epoch [13/200], Validation Loss: 0.0894
Epoch [14/200], Average Training Loss: 0.1057
Epoch [14/200], Validation Loss: 0.0959
Epoch [15/200], Average Training Loss: 0.1003
Epoch [15/200], Validation Loss: 0.0901
Epoch [16/200], Average Training Loss: 0.0958
Epoch [16/200], Validation Loss: 0.0875
Epoch [17/200], Average Training Loss: 0.0922
Epoch [17/200], Validation Loss: 0.0864
Epoch [18/200], Average Training Loss: 0.0859
Epoch [18/200], Validation Loss: 0.0893
Epoch [19/200], Average Training Loss: 0.0795
Epoch [19/200], Validation Loss: 0.0895
Epoch [20/200], Average Training Loss: 0.0743
Epoch [20/200], Validation Loss: 0.0892
Epoch [21/200], Average Training Loss: 0.0720
Epoch [21/200], Validation Loss: 0.0830
Epoch [22/200], Average Training Loss: 0.0703
Epoch [22/200], Validation Loss: 0.0864
Epoch [23/200], Average Training Loss: 0.0659
Epoch [23/200], Validation Loss: 0.0863
Epoch [24/200], Average Training Loss: 0.0643
Epoch [24/200], Validation Loss: 0.0850
Epoch [25/200], Average Training Loss: 0.0628
Epoch [25/200], Validation Loss: 0.0881
Epoch [26/200], Average Training Loss: 0.0646
Epoch [26/200], Validation Loss: 0.0833
Epoch [27/200], Average Training Loss: 0.0565
Epoch [27/200], Validation Loss: 0.0839
Epoch [28/200], Average Training Loss: 0.0569
Epoch [28/200], Validation Loss: 0.0856
Epoch [29/200], Average Training Loss: 0.0527
Epoch [29/200], Validation Loss: 0.0806
Epoch [30/200], Average Training Loss: 0.0525
Epoch [30/200], Validation Loss: 0.0798
Epoch [31/200], Average Training Loss: 0.0487
Epoch [31/200], Validation Loss: 0.0853
Epoch [32/200], Average Training Loss: 0.0477
Epoch [32/200], Validation Loss: 0.0791
Epoch [33/200], Average Training Loss: 0.0474
Epoch [33/200], Validation Loss: 0.0863
Epoch [34/200], Average Training Loss: 0.0463
Epoch [34/200], Validation Loss: 0.0823
Epoch [35/200], Average Training Loss: 0.0426
Epoch [35/200], Validation Loss: 0.0727
Epoch [36/200], Average Training Loss: 0.0412
Epoch [36/200], Validation Loss: 0.0813
Epoch [37/200], Average Training Loss: 0.0410
Epoch [37/200], Validation Loss: 0.0804
Epoch [38/200], Average Training Loss: 0.0394
Epoch [38/200], Validation Loss: 0.0756
Epoch [39/200], Average Training Loss: 0.0355
Epoch [39/200], Validation Loss: 0.0793
Epoch [40/200], Average Training Loss: 0.0357
Epoch [40/200], Validation Loss: 0.0760
Epoch [41/200], Average Training Loss: 0.0363
Epoch [41/200], Validation Loss: 0.0792
Epoch [42/200], Average Training Loss: 0.0348
Epoch [42/200], Validation Loss: 0.0782
Epoch [43/200], Average Training Loss: 0.0324
Epoch [43/200], Validation Loss: 0.0747
Epoch [44/200], Average Training Loss: 0.0331
Epoch [44/200], Validation Loss: 0.0750
Epoch [45/200], Average Training Loss: 0.0347
Epoch [45/200], Validation Loss: 0.0777
Epoch [46/200], Average Training Loss: 0.0291
Epoch [46/200], Validation Loss: 0.0757
Epoch [47/200], Average Training Loss: 0.0321
Epoch [47/200], Validation Loss: 0.0745
Epoch [48/200], Average Training Loss: 0.0282
Epoch [48/200], Validation Loss: 0.0765
Epoch [49/200], Average Training Loss: 0.0275
Epoch [49/200], Validation Loss: 0.0735
Epoch [50/200], Average Training Loss: 0.0273
Epoch [50/200], Validation Loss: 0.0760
Epoch [51/200], Average Training Loss: 0.0257
Epoch [51/200], Validation Loss: 0.0786
Epoch [52/200], Average Training Loss: 0.0262
Epoch [52/200], Validation Loss: 0.0739
Epoch [53/200], Average Training Loss: 0.0256
Epoch [53/200], Validation Loss: 0.0730
Epoch [54/200], Average Training Loss: 0.0240
Epoch [54/200], Validation Loss: 0.0764
Epoch [55/200], Average Training Loss: 0.0244
Epoch [55/200], Validation Loss: 0.0750
Early stopping at epoch 55
Finished Training
Best parameters found: {'batch_size': 8, 'learning_rate': 0.0001}
Testing best CNN Model:
Epoch [1/200], Average Training Loss: 0.2046
Epoch [1/200], Validation Loss: 0.1494
Epoch [2/200], Average Training Loss: 0.1736
Epoch [2/200], Validation Loss: 0.1411
Epoch [3/200], Average Training Loss: 0.1612
Epoch [3/200], Validation Loss: 0.1137
Epoch [4/200], Average Training Loss: 0.1498
Epoch [4/200], Validation Loss: 0.1098
Epoch [5/200], Average Training Loss: 0.1422
Epoch [5/200], Validation Loss: 0.1144
Epoch [6/200], Average Training Loss: 0.1380
Epoch [6/200], Validation Loss: 0.1051
Epoch [7/200], Average Training Loss: 0.1309
Epoch [7/200], Validation Loss: 0.1093
Epoch [8/200], Average Training Loss: 0.1259
Epoch [8/200], Validation Loss: 0.0949
Epoch [9/200], Average Training Loss: 0.1191
Epoch [9/200], Validation Loss: 0.0928
Epoch [10/200], Average Training Loss: 0.1069
Epoch [10/200], Validation Loss: 0.0910
Epoch [11/200], Average Training Loss: 0.1031
Epoch [11/200], Validation Loss: 0.0847
Epoch [12/200], Average Training Loss: 0.0976
Epoch [12/200], Validation Loss: 0.0852
Epoch [13/200], Average Training Loss: 0.0909
Epoch [13/200], Validation Loss: 0.0889
Epoch [14/200], Average Training Loss: 0.0869
Epoch [14/200], Validation Loss: 0.0836
Epoch [15/200], Average Training Loss: 0.0784
Epoch [15/200], Validation Loss: 0.0842
Epoch [16/200], Average Training Loss: 0.0751
Epoch [16/200], Validation Loss: 0.0877
Epoch [17/200], Average Training Loss: 0.0716
Epoch [17/200], Validation Loss: 0.0803
Epoch [18/200], Average Training Loss: 0.0678
Epoch [18/200], Validation Loss: 0.0801
Epoch [19/200], Average Training Loss: 0.0652
Epoch [19/200], Validation Loss: 0.0747
Epoch [20/200], Average Training Loss: 0.0606
Epoch [20/200], Validation Loss: 0.0797
Epoch [21/200], Average Training Loss: 0.0582
Epoch [21/200], Validation Loss: 0.0765
Epoch [22/200], Average Training Loss: 0.0553
Epoch [22/200], Validation Loss: 0.0720
Epoch [23/200], Average Training Loss: 0.0521
Epoch [23/200], Validation Loss: 0.0761
Epoch [24/200], Average Training Loss: 0.0520
Epoch [24/200], Validation Loss: 0.0717
Epoch [25/200], Average Training Loss: 0.0477
Epoch [25/200], Validation Loss: 0.0713
Epoch [26/200], Average Training Loss: 0.0449
Epoch [26/200], Validation Loss: 0.0771
Epoch [27/200], Average Training Loss: 0.0450
Epoch [27/200], Validation Loss: 0.0766
Epoch [28/200], Average Training Loss: 0.0429
Epoch [28/200], Validation Loss: 0.0741
Epoch [29/200], Average Training Loss: 0.0384
Epoch [29/200], Validation Loss: 0.0741
Epoch [30/200], Average Training Loss: 0.0382
Epoch [30/200], Validation Loss: 0.0734
Epoch [31/200], Average Training Loss: 0.0368
Epoch [31/200], Validation Loss: 0.0753
Epoch [32/200], Average Training Loss: 0.0347
Epoch [32/200], Validation Loss: 0.0674
Epoch [33/200], Average Training Loss: 0.0351
Epoch [33/200], Validation Loss: 0.0709
Epoch [34/200], Average Training Loss: 0.0339
Epoch [34/200], Validation Loss: 0.0682
Epoch [35/200], Average Training Loss: 0.0316
Epoch [35/200], Validation Loss: 0.0670
Epoch [36/200], Average Training Loss: 0.0306
Epoch [36/200], Validation Loss: 0.0719
Epoch [37/200], Average Training Loss: 0.0292
Epoch [37/200], Validation Loss: 0.0715
Epoch [38/200], Average Training Loss: 0.0280
Epoch [38/200], Validation Loss: 0.0679
Epoch [39/200], Average Training Loss: 0.0267
Epoch [39/200], Validation Loss: 0.0743
Epoch [40/200], Average Training Loss: 0.0250
Epoch [40/200], Validation Loss: 0.0677
Epoch [41/200], Average Training Loss: 0.0253
Epoch [41/200], Validation Loss: 0.0723
Epoch [42/200], Average Training Loss: 0.0252
Epoch [42/200], Validation Loss: 0.0683
Epoch [43/200], Average Training Loss: 0.0250
Epoch [43/200], Validation Loss: 0.0671
Epoch [44/200], Average Training Loss: 0.0223
Epoch [44/200], Validation Loss: 0.0696
Epoch [45/200], Average Training Loss: 0.0235
Epoch [45/200], Validation Loss: 0.0664
Epoch [46/200], Average Training Loss: 0.0229
Epoch [46/200], Validation Loss: 0.0655
Epoch [47/200], Average Training Loss: 0.0221
Epoch [47/200], Validation Loss: 0.0667
Epoch [48/200], Average Training Loss: 0.0215
Epoch [48/200], Validation Loss: 0.0660
Epoch [49/200], Average Training Loss: 0.0203
Epoch [49/200], Validation Loss: 0.0678
Epoch [50/200], Average Training Loss: 0.0201
Epoch [50/200], Validation Loss: 0.0661
Epoch [51/200], Average Training Loss: 0.0190
Epoch [51/200], Validation Loss: 0.0653
Epoch [52/200], Average Training Loss: 0.0196
Epoch [52/200], Validation Loss: 0.0656
Epoch [53/200], Average Training Loss: 0.0189
Epoch [53/200], Validation Loss: 0.0648
Epoch [54/200], Average Training Loss: 0.0181
Epoch [54/200], Validation Loss: 0.0655
Epoch [55/200], Average Training Loss: 0.0177
Epoch [55/200], Validation Loss: 0.0663
Epoch [56/200], Average Training Loss: 0.0175
Epoch [56/200], Validation Loss: 0.0658
Epoch [57/200], Average Training Loss: 0.0170
Epoch [57/200], Validation Loss: 0.0642
Epoch [58/200], Average Training Loss: 0.0168
Epoch [58/200], Validation Loss: 0.0638
Epoch [59/200], Average Training Loss: 0.0165
Epoch [59/200], Validation Loss: 0.0677
Epoch [60/200], Average Training Loss: 0.0162
Epoch [60/200], Validation Loss: 0.0670
Epoch [61/200], Average Training Loss: 0.0156
Epoch [61/200], Validation Loss: 0.0695
Epoch [62/200], Average Training Loss: 0.0154
Epoch [62/200], Validation Loss: 0.0650
Epoch [63/200], Average Training Loss: 0.0155
Epoch [63/200], Validation Loss: 0.0662
Epoch [64/200], Average Training Loss: 0.0154
Epoch [64/200], Validation Loss: 0.0658
Epoch [65/200], Average Training Loss: 0.0149
Epoch [65/200], Validation Loss: 0.0625
Epoch [66/200], Average Training Loss: 0.0141
Epoch [66/200], Validation Loss: 0.0674
Epoch [67/200], Average Training Loss: 0.0145
Epoch [67/200], Validation Loss: 0.0649
Epoch [68/200], Average Training Loss: 0.0140
Epoch [68/200], Validation Loss: 0.0645
Epoch [69/200], Average Training Loss: 0.0134
Epoch [69/200], Validation Loss: 0.0642
Epoch [70/200], Average Training Loss: 0.0136
Epoch [70/200], Validation Loss: 0.0664
Epoch [71/200], Average Training Loss: 0.0134
Epoch [71/200], Validation Loss: 0.0620
Epoch [72/200], Average Training Loss: 0.0131
Epoch [72/200], Validation Loss: 0.0641
Epoch [73/200], Average Training Loss: 0.0127
Epoch [73/200], Validation Loss: 0.0647
Epoch [74/200], Average Training Loss: 0.0128
Epoch [74/200], Validation Loss: 0.0675
Epoch [75/200], Average Training Loss: 0.0126
Epoch [75/200], Validation Loss: 0.0627
Epoch [76/200], Average Training Loss: 0.0123
Epoch [76/200], Validation Loss: 0.0616
Epoch [77/200], Average Training Loss: 0.0116
Epoch [77/200], Validation Loss: 0.0658
Epoch [78/200], Average Training Loss: 0.0117
Epoch [78/200], Validation Loss: 0.0629
Epoch [79/200], Average Training Loss: 0.0122
Epoch [79/200], Validation Loss: 0.0644
Epoch [80/200], Average Training Loss: 0.0118
Epoch [80/200], Validation Loss: 0.0625
Epoch [81/200], Average Training Loss: 0.0119
Epoch [81/200], Validation Loss: 0.0653
Epoch [82/200], Average Training Loss: 0.0115
Epoch [82/200], Validation Loss: 0.0621
Epoch [83/200], Average Training Loss: 0.0114
Epoch [83/200], Validation Loss: 0.0629
Epoch [84/200], Average Training Loss: 0.0112
Epoch [84/200], Validation Loss: 0.0645
Epoch [85/200], Average Training Loss: 0.0109
Epoch [85/200], Validation Loss: 0.0646
Epoch [86/200], Average Training Loss: 0.0113
Epoch [86/200], Validation Loss: 0.0620
Epoch [87/200], Average Training Loss: 0.0107
Epoch [87/200], Validation Loss: 0.0640
Epoch [88/200], Average Training Loss: 0.0105
Epoch [88/200], Validation Loss: 0.0628
Epoch [89/200], Average Training Loss: 0.0103
Epoch [89/200], Validation Loss: 0.0606
Epoch [90/200], Average Training Loss: 0.0107
Epoch [90/200], Validation Loss: 0.0602
Epoch [91/200], Average Training Loss: 0.0104
Epoch [91/200], Validation Loss: 0.0615
Epoch [92/200], Average Training Loss: 0.0097
Epoch [92/200], Validation Loss: 0.0615
Epoch [93/200], Average Training Loss: 0.0099
Epoch [93/200], Validation Loss: 0.0614
Epoch [94/200], Average Training Loss: 0.0098
Epoch [94/200], Validation Loss: 0.0610
Epoch [95/200], Average Training Loss: 0.0098
Epoch [95/200], Validation Loss: 0.0591
Epoch [96/200], Average Training Loss: 0.0095
Epoch [96/200], Validation Loss: 0.0594
Epoch [97/200], Average Training Loss: 0.0099
Epoch [97/200], Validation Loss: 0.0615
Epoch [98/200], Average Training Loss: 0.0096
Epoch [98/200], Validation Loss: 0.0628
Epoch [99/200], Average Training Loss: 0.0093
Epoch [99/200], Validation Loss: 0.0618
Epoch [100/200], Average Training Loss: 0.0094
Epoch [100/200], Validation Loss: 0.0638
Epoch [101/200], Average Training Loss: 0.0093
Epoch [101/200], Validation Loss: 0.0595
Epoch [102/200], Average Training Loss: 0.0093
Epoch [102/200], Validation Loss: 0.0591
Epoch [103/200], Average Training Loss: 0.0091
Epoch [103/200], Validation Loss: 0.0633
Epoch [104/200], Average Training Loss: 0.0086
Epoch [104/200], Validation Loss: 0.0570
Epoch [105/200], Average Training Loss: 0.0087
Epoch [105/200], Validation Loss: 0.0608
Epoch [106/200], Average Training Loss: 0.0087
Epoch [106/200], Validation Loss: 0.0579
Epoch [107/200], Average Training Loss: 0.0086
Epoch [107/200], Validation Loss: 0.0626
Epoch [108/200], Average Training Loss: 0.0088
Epoch [108/200], Validation Loss: 0.0647
Epoch [109/200], Average Training Loss: 0.0087
Epoch [109/200], Validation Loss: 0.0607
Epoch [110/200], Average Training Loss: 0.0082
Epoch [110/200], Validation Loss: 0.0606
Epoch [111/200], Average Training Loss: 0.0082
Epoch [111/200], Validation Loss: 0.0621
Epoch [112/200], Average Training Loss: 0.0081
Epoch [112/200], Validation Loss: 0.0605
Epoch [113/200], Average Training Loss: 0.0084
Epoch [113/200], Validation Loss: 0.0614
Epoch [114/200], Average Training Loss: 0.0082
Epoch [114/200], Validation Loss: 0.0614
Epoch [115/200], Average Training Loss: 0.0077
Epoch [115/200], Validation Loss: 0.0615
Epoch [116/200], Average Training Loss: 0.0080
Epoch [116/200], Validation Loss: 0.0617
Epoch [117/200], Average Training Loss: 0.0078
Epoch [117/200], Validation Loss: 0.0605
Epoch [118/200], Average Training Loss: 0.0078
Epoch [118/200], Validation Loss: 0.0611
Epoch [119/200], Average Training Loss: 0.0079
Epoch [119/200], Validation Loss: 0.0624
Epoch [120/200], Average Training Loss: 0.0076
Epoch [120/200], Validation Loss: 0.0585
Epoch [121/200], Average Training Loss: 0.0078
Epoch [121/200], Validation Loss: 0.0616
Epoch [122/200], Average Training Loss: 0.0074
Epoch [122/200], Validation Loss: 0.0625
Epoch [123/200], Average Training Loss: 0.0075
Epoch [123/200], Validation Loss: 0.0618
Epoch [124/200], Average Training Loss: 0.0071
Epoch [124/200], Validation Loss: 0.0586
Early stopping at epoch 124
Finished Training
Test Loss: 0.0559
Final Training Loss: 0.0071
Final Validation Loss: 0.0586
Test Loss: 0.0559
